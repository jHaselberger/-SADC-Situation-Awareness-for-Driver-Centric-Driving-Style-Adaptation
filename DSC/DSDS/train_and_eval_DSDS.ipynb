{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../evaluation\")\n",
    "sys.path.append(\"../utils\")\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import copy\n",
    "import importlib\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from LUT import LUT_1D\n",
    "from matplotlib import pyplot as plt\n",
    "import plot_helpers\n",
    "from warnings import simplefilter\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "simplefilter(\"ignore\", category=ConvergenceWarning)\n",
    "simplefilter(action=\"ignore\", category=pd.errors.PerformanceWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpter Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filtered_dataset(df, max_d2cl=0.8, min_d2cl=0, filter_rural=False):\n",
    "    _df = copy.deepcopy(df)\n",
    "    _df = _df[_df.Dist_To_Center_Lane.abs() < max_d2cl]\n",
    "    _df = _df[_df.Dist_To_Center_Lane.abs() > min_d2cl]\n",
    "\n",
    "    if filter_rural:\n",
    "        _df = _df[_df.road_type == \"rural\"]\n",
    "\n",
    "    return _df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_D2CL_TRAIN = 1.5\n",
    "MAX_D2CL_EVAL = 0.8 # 0.8\n",
    "MIN_D2CL_EVAL = 0\n",
    "\n",
    "SEGMENT_KEY = \"frame\" # \"frame\" or \"segment\"\n",
    "# N_SPLITS = 10\n",
    "\n",
    "VERBOSE = False\n",
    "\n",
    "FILTER_RURAL = False\n",
    "DOMAIN = \"all\" if not FILTER_RURAL else \"rural_only\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = \"val-pretrain\"\n",
    "step_count = 10\n",
    "\n",
    "iterative_training_splits_df = pd.read_pickle(\n",
    "    f\"./dataset_val_train_iterative_training_splits_{DOMAIN}_{step_count}_splits.pkl\"\n",
    ")\n",
    "\n",
    "dataset_dir = \"/root/sadc/data/datasets\"\n",
    "data_lake = \"/root/sadc/results\"\n",
    "\n",
    "config = {\n",
    "    \"val-pretrain\":{\n",
    "        \"DSC\": \"sadc_clustering_resnet_18_val_all_13-01-2024_15-45-37\",\n",
    "        \"DSC_run_name\": \"sadc_clustering_resnet_18_val_all_13-01-2024_15-45-37\",\n",
    "        \"best_c_id\": 500,\n",
    "        \"NN-IT\": {\n",
    "            10: \"resnet18_all_r1/heads/mlp_stepwise_10/predictions_stepwise/val_val/driving_data_predictions.pkl\",\n",
    "        }\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "val_train_df = pd.read_pickle(os.path.join(dataset_dir, \"dataset_val_train.pkl\"))\n",
    "val_val_df = pd.read_pickle(os.path.join(dataset_dir, \"dataset_val_val.pkl\"))\n",
    "\n",
    "sadc_clustering_val_train_df = pd.read_pickle(os.path.join(data_lake,config[run][\"DSC\"],f\"{config[run]['DSC_run_name']}_val_train.pkl\"))\n",
    "sadc_clustering_val_val_df = pd.read_pickle(os.path.join(data_lake,config[run][\"DSC\"],f\"{config[run]['DSC_run_name']}_val_val.pkl\"))\n",
    "mlp_stepwise_predictions_df = pd.read_pickle(os.path.join(data_lake,config[run][\"NN-IT\"][step_count]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_train_df = get_filtered_dataset(df=val_train_df,max_d2cl=MAX_D2CL_TRAIN,filter_rural=FILTER_RURAL)\n",
    "val_val_df = get_filtered_dataset(df=val_val_df,max_d2cl=MAX_D2CL_EVAL,min_d2cl=MIN_D2CL_EVAL,filter_rural=FILTER_RURAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge with Cluster IDs and Training Iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cid = f\"fkm_{config[run]['best_c_id']}_cluster_id\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sadc_clustering_val_train_df = sadc_clustering_val_train_df[[\"alias\",\"frame\",cid]]\n",
    "sadc_clustering_val_val_df = sadc_clustering_val_val_df[[\"alias\",\"frame\",cid]]\n",
    "\n",
    "val_train_df = val_train_df.merge(iterative_training_splits_df,how=\"left\",on=[\"alias\",\"frame\"])\n",
    "val_train_df = val_train_df.merge(sadc_clustering_val_train_df,how=\"left\",on=[\"alias\",\"frame\"])\n",
    "\n",
    "val_val_df = val_val_df.merge(sadc_clustering_val_val_df,how=\"left\",on=[\"alias\",\"frame\"])\n",
    "\n",
    "mlp_pred_cols = [c for c in mlp_stepwise_predictions_df.columns if \"predictions\" in c]\n",
    "val_val_df = val_val_df.merge(mlp_stepwise_predictions_df[[\"alias\",\"frame\",*mlp_pred_cols]],how=\"left\",on=[\"alias\",\"frame\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_luts = {}\n",
    "DEFAULT_VALUE = 0.0\n",
    "VERBOSE = False\n",
    "LUT_STORE_ALL_DATA = True\n",
    "\n",
    "\n",
    "for alias in tqdm(val_train_df.alias.unique(),desc=\"Training\"):\n",
    "    trained_luts[alias] = {}\n",
    "    _df_alias = val_train_df[val_train_df.alias == alias]\n",
    "\n",
    "    _lut = LUT_1D(default_value=DEFAULT_VALUE, verbose=VERBOSE, store_all_data = LUT_STORE_ALL_DATA)\n",
    "\n",
    "    for it in _df_alias[\"train_iter\"].unique():\n",
    "        _df_alias_it = _df_alias[_df_alias[\"train_iter\"] == it]\n",
    "        for i, row in tqdm(\n",
    "            _df_alias_it.iterrows(),\n",
    "            total=len(_df_alias_it.index),\n",
    "            desc=f\"Training iteration {it} for alias {alias}\",\n",
    "            disable=True\n",
    "        ):\n",
    "            _lut.train_sample(index=row[cid], key=\"D2CL\", value=row.Dist_To_Center_Lane)\n",
    "        trained_luts[alias][it] = copy.deepcopy(_lut)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(alias, index, key, training_iteration, trained_luts):\n",
    "    lut = trained_luts[alias][training_iteration]\n",
    "    mean, std = lut.get_mean_std(index=index, key=key)\n",
    "    return mean, std\n",
    "\n",
    "\n",
    "v_get_predictions = np.vectorize(\n",
    "    get_predictions, excluded=[\"key\", \"training_iteration\", \"trained_luts\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for training_iteration in tqdm(iterative_training_splits_df.train_iter.unique()):\n",
    "    (\n",
    "        val_val_df[f\"lut_D2CL_it_{training_iteration}_mean\"],\n",
    "        val_val_df[f\"lut_D2CL_it_{training_iteration}_std\"],\n",
    "    ) = v_get_predictions(\n",
    "        alias=val_val_df.alias,\n",
    "        index=val_val_df[cid],\n",
    "        key=\"D2CL\",\n",
    "        training_iteration=training_iteration,\n",
    "        trained_luts=trained_luts,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(df, key, zero_shape):\n",
    "    if key in df.columns:\n",
    "        return df[key]\n",
    "    else:\n",
    "        return np.zeros_like(zero_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for training_iteration in tqdm(iterative_training_splits_df.train_iter.unique()):\n",
    "    for alias in val_val_df.alias.unique():\n",
    "        _d = val_val_df[val_val_df.alias == alias]\n",
    "        _d_y_true = _d[\"Dist_To_Center_Lane\"]\n",
    "        _d_y_predicted_lut = _d[f\"lut_D2CL_it_{training_iteration}_mean\"]\n",
    "        _d_y_predicted_mlp = get_predictions(_d,f\"predictions_{training_iteration}\",_d_y_true)\n",
    "\n",
    "        results.append(\n",
    "            {\n",
    "                \"training_iteration\": training_iteration,\n",
    "                \"alias\": alias,\n",
    "                \"rmse_lut\": mean_squared_error(\n",
    "                    _d_y_true, _d_y_predicted_lut, squared=False\n",
    "                ),\n",
    "                \"rmse_mlp\": mean_squared_error(\n",
    "                    _d_y_true, _d_y_predicted_mlp, squared=False\n",
    "                ),\n",
    "                \"mse_lut\": mean_squared_error(_d_y_true, _d_y_predicted_lut),\n",
    "                \"mse_mlp\": mean_squared_error(_d_y_true, _d_y_predicted_mlp),\n",
    "            }\n",
    "        )\n",
    "\n",
    "results_df = pd.DataFrame.from_dict(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterative Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(plot_helpers)\n",
    "plt.close()\n",
    "t = None\n",
    "t = f\"./final_iterative_plots/{run}_{step_count}_steps.pdf\"\n",
    "plot_helpers.plot_iterative_training(\n",
    "    results_df=results_df,\n",
    "    marker_size=1,\n",
    "    figsize=(2, 2),\n",
    "    y_lim=(0.05, 0.95),\n",
    "    legend_y_pad=-0.32,\n",
    "    target=t,\n",
    "    x_ticks=[int(i * step_count / 5) for i in range(6)],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster wise Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANGE = (-0.8, 0.8)\n",
    "N_BINS = 40\n",
    "FIGSIZE = (2, 2)\n",
    "KED_LINEWIDTH = 1.5\n",
    "context = [\"science\", \"ieee\", \"no-latex\"]\n",
    "legend_y_pad = -0.3\n",
    "\n",
    "for cluster_id in tqdm(trained_luts[\"001\"][9]._lut.keys()):\n",
    "\n",
    "    try:\n",
    "        data_001 = trained_luts[\"001\"][9]._lut[cluster_id][\"D2CL\"][\"data\"]\n",
    "        data_002 = trained_luts[\"002\"][9]._lut[cluster_id][\"D2CL\"][\"data\"]\n",
    "        data_003 = trained_luts[\"003\"][9]._lut[cluster_id][\"D2CL\"][\"data\"]\n",
    "        data_004 = trained_luts[\"004\"][9]._lut[cluster_id][\"D2CL\"][\"data\"]\n",
    "        data_005 = trained_luts[\"005\"][9]._lut[cluster_id][\"D2CL\"][\"data\"]\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    with plt.style.context(context):\n",
    "        fig, ax = plt.subplots(figsize=FIGSIZE)\n",
    "\n",
    "        plot_helpers.plot_hist(\n",
    "            data_001,\n",
    "            ax=ax,\n",
    "            range=RANGE,\n",
    "            n_bins=N_BINS,\n",
    "            bar_alpha=0.25,\n",
    "            color=\"k\",\n",
    "            fill_color=\"k\",\n",
    "            edgecolor=\"k\",\n",
    "            kde_linestyle=\"-\",\n",
    "            kde_linewidth=KED_LINEWIDTH,\n",
    "            show_bar=False,\n",
    "            label=\"001\",\n",
    "        )\n",
    "        plot_helpers.plot_hist(\n",
    "            data_002,\n",
    "            ax=ax,\n",
    "            range=RANGE,\n",
    "            n_bins=N_BINS,\n",
    "            bar_alpha=0.25,\n",
    "            color=\"r\",\n",
    "            fill_color=\"r\",\n",
    "            edgecolor=\"r\",\n",
    "            kde_linestyle=\"-\",\n",
    "            kde_linewidth=KED_LINEWIDTH,\n",
    "            show_bar=False,\n",
    "            label=\"002\",\n",
    "        )\n",
    "        plot_helpers.plot_hist(\n",
    "            data_003,\n",
    "            ax=ax,\n",
    "            range=RANGE,\n",
    "            n_bins=N_BINS,\n",
    "            bar_alpha=0.25,\n",
    "            color=\"k\",\n",
    "            fill_color=\"k\",\n",
    "            edgecolor=\"k\",\n",
    "            kde_linestyle=\"--\",\n",
    "            kde_linewidth=KED_LINEWIDTH,\n",
    "            show_bar=False,\n",
    "            label=\"003\",\n",
    "        )\n",
    "        plot_helpers.plot_hist(\n",
    "            data_004,\n",
    "            ax=ax,\n",
    "            range=RANGE,\n",
    "            n_bins=N_BINS,\n",
    "            bar_alpha=0.25,\n",
    "            color=\"r\",\n",
    "            fill_color=\"r\",\n",
    "            edgecolor=\"r\",\n",
    "            kde_linestyle=\"--\",\n",
    "            kde_linewidth=KED_LINEWIDTH,\n",
    "            show_bar=False,\n",
    "            label=\"004\",\n",
    "        )\n",
    "        plot_helpers.plot_hist(\n",
    "            data_005,\n",
    "            ax=ax,\n",
    "            range=RANGE,\n",
    "            n_bins=N_BINS,\n",
    "            bar_alpha=0.25,\n",
    "            color=\"k\",\n",
    "            fill_color=\"w\",\n",
    "            edgecolor=\"k\",\n",
    "            kde_linestyle=\":\",\n",
    "            kde_linewidth=KED_LINEWIDTH,\n",
    "            show_bar=False,\n",
    "            label=\"005\",\n",
    "        )\n",
    "\n",
    "        plt.xlabel(r\"$d_{\\mathrm{CL}}$ in $m$\")\n",
    "\n",
    "        plt.legend(ncols=5, loc=\"center\", bbox_to_anchor=(0.5, legend_y_pad))\n",
    "        plt.xlim(RANGE[1], RANGE[0])\n",
    "        plt.savefig(f\"./hist_plots_resnext50/hist_plot_{cluster_id}.pdf\")\n",
    "        plt.savefig(f\"./hist_plots_resnext50/hist_plot_{cluster_id}.png\")\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot predicted Trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IT = 199\n",
    "CID = cid\n",
    "n_frames = 6\n",
    "\n",
    "v_df = copy.deepcopy(val_val_df)\n",
    "v_df[f\"{CID}_d2cl_mean\"] = v_df[f\"lut_D2CL_it_{IT}_mean\"]\n",
    "v_df[f\"{CID}_d2cl_std\"] = v_df[f\"lut_D2CL_it_{IT}_std\"]\n",
    "\n",
    "\n",
    "for alias in v_df.alias.unique():\n",
    "    _v_a = v_df[v_df.alias == alias]\n",
    "\n",
    "    for s in tqdm(_v_a.segment.unique()):\n",
    "        _v_a_s = _v_a[_v_a.segment == s]\n",
    "\n",
    "        step_size = (_v_a_s.frame.max() - _v_a_s.frame.min()) / (n_frames - 1)\n",
    "        frame_markers = [int(_v_a_s.frame.min() + i * step_size) for i in range(n_frames)]\n",
    "        frame_markers_closest = [min(_v_a_s.frame.tolist(), key=lambda x:abs(x-f)) for f in frame_markers]\n",
    "        frame_cluster_annotations = _v_a_s[_v_a_s.frame.isin(frame_markers_closest)][CID].tolist()\n",
    "\n",
    "        if len(frame_markers_closest) != len(frame_cluster_annotations):\n",
    "            print(f\"Skipping {alias}-->{s}\")\n",
    "            continue\n",
    "\n",
    "        plot_helpers.plotSituationPredictions(\n",
    "            df=_v_a_s,\n",
    "            cID=CID,\n",
    "            target=f\"./sit_plots_with_nr_nc/{alias}_{s}.pdf\",\n",
    "            mlp_predictions=_v_a_s.predictions.to_numpy(),\n",
    "            std_alpha=0.1,\n",
    "            cluster_marker_size=10,\n",
    "            figsize=(1.8, 1.5),\n",
    "            legend_below_plot=True,\n",
    "            fill_cluster_marker=False,\n",
    "            cluster_marker_color=\"r\",\n",
    "            annotate_cluster_markers = False,\n",
    "            legend_y_pad = -0.35,\n",
    "            legend_n_cols = 4,\n",
    "            frame_markers=frame_markers_closest,\n",
    "            frame_cluster_annotations= frame_cluster_annotations,\n",
    "            y_lim = 0.8\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Situation Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_frames = 6\n",
    "collageSize = (600, 400)\n",
    "imagesRoot = \"/root/sadc/data/images/val/\"\n",
    "targetFolder = \"./sit_set_cards_with_nr/\"\n",
    "\n",
    "for alias in v_df.alias.unique():\n",
    "    _v_a = v_df[v_df.alias == alias]\n",
    "\n",
    "    for s in tqdm(_v_a.segment.unique()):\n",
    "        _v_a_s = _v_a[_v_a.segment == s]\n",
    "\n",
    "        step_size = (_v_a_s.frame.max() - _v_a_s.frame.min()) / (n_frames - 1)\n",
    "        frames = [\n",
    "            plot_helpers.get_frame(\n",
    "                imagesRoot=imagesRoot,\n",
    "                alias=alias,\n",
    "                frame=int(_v_a_s.frame.min() + i * step_size),\n",
    "            )\n",
    "            for i in range(n_frames)\n",
    "        ]\n",
    "\n",
    "        c = plot_helpers.createCollage(frames, collageSize)\n",
    "        c.save(f\"{targetFolder}/{alias}_{s}_samples.jpg\", optimize=True, quality=95)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "USADC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
